\documentclass{article}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{amsthm}
\newtheorem{theorem}{Theorem}[section]
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{corollary}[theorem]{Corollary}
\renewcommand*{\proofname}{Proof}
\theoremstyle{definition}
\newtheorem{definition}{Definition}[section]
\theoremstyle{remark}
\newtheorem*{remark}{Remark}
\theoremstyle{example}
\newtheorem{example}{Example}[section]
\theoremstyle{notation}
\newtheorem{notation}{Notation}[section]
\DeclareMathOperator*{\argmax}{arg\,max}
\usepackage{fullpage}
\usepackage{outlines}
\usepackage{bbm}
\usepackage{physics}
\usepackage{xparse}
\usepackage{mathtools}
\allowdisplaybreaks

\newcommand{\tif}{\text{if }}
\newcommand{\lr}[1]{\left({#1}\right)}
\newcommand{\E}[1]{\mathbb{E}[#1]}
\newcommand{\V}[1]{\mathbb{V}[#1]}
\newcommand{\pr}{\mathbf{pr}}

\let\P\relax
\NewDocumentCommand{\P}{o}{\mathbb{P}\IfValueT{#1}{\left[#1\right]}}


\title{Measure Theory}
\author{Lysandre Terrisse}

\begin{document}
\maketitle

%https://www.math.lsu.edu/~sengupta/7312s02/sigmaalg.pdf
%https://moodle.umontpellier.fr/pluginfile.php/2373208/mod_resource/content/12/HAX503X-poly.pdf

\section{Measurable space and $\sigma$-algebra}

\begin{definition}[Measurable space and $\sigma$-algebra]
    Let $X$ be a set. A \textit{measurable space} is a couple $(X, \mathcal{A})$ where $\mathcal{A}$ is a \textit{$\sigma$-algebra} of $X$. That is, $\mathcal{A}$ is a set of subsets of $X$, called \textit{measurable sets}, such that:
    \begin{itemize}
        \item $X$ is a measurable set:
            $$X \in \mathcal{A}$$
        \item Complements of measurable sets are measurable:
            $$\forall A \in \mathcal{A}, A^c \in \mathcal{A}$$
        \item Countable unions of measurable sets are measurable: For all countable family $(A_i)_{i \in \mathbb{N}}$ of measurable sets:
            $$\bigcup_{i \in \mathbb{N}} A_i \in \mathcal{A}$$
    \end{itemize}
\end{definition}

\begin{theorem}[Countable intersections of measurable sets are measurable]
    Let $(X, \mathcal{A})$ be a measurable space, and let $(A_i)_{i \in \mathbb{N}}$ be a countable family over measurable sets. Then:
            $$\bigcap_{i \in \mathbb{N}} A_i \in \mathcal{A}$$
\end{theorem}

\begin{proof}
		For all $i \in \mathbb{N}$, as $A_i \in \mathcal{A}$, then $A_i^c \in \mathcal{A}$, and thus $\bigcup_{i \in \mathbb{N}} A_i^c \in \mathcal{A}$, so $\left(\bigcup_{i \in \mathbb{N}} A_i^c\right)^c = \bigcap_{i \in \mathbb{N}} A_i \in \mathcal{A}$.
\end{proof}

\begin{definition}[Trivial and full $\sigma$-algebra]
    Let $X$ be a set. The \textit{trivial $\sigma$-algebra} is $\{\varnothing, X\}$, and the \textit{full $\sigma$-algebra} is $\mathcal{P}(X)$. They indeed are $\sigma$-algebras, since $X$ belongs to them, and that they are stable over complements and countable unions.
\end{definition}

\begin{theorem}[$\sigma$-algebra are between the trivial and full $\sigma$-algebras]
    For all measurable space $(X, \mathcal{A})$, we have:
        $$\{\varnothing, X\} \subseteq \mathcal{A} \subseteq \mathcal{P}(X)$$
\end{theorem}

\begin{proof}
    Since $X \in \mathcal{A}$, and that $\mathcal{A}$ is closed under complement, then $X^c = X \setminus X = \varnothing \in \mathcal{A}$. Therefore, $\{\varnothing, X\} \subseteq \mathcal{A}$. Furthermore, from the definition of $\sigma$-algebra, $\mathcal{A} \subseteq \mathcal{P}(X)$. 
\end{proof}

\begin{remark}
    This theorem implies that the trivial and the full $\sigma$-algebras are respectively the smallest and biggest $\sigma$-algebras. By \textit{smallest}, we mean that all other $\sigma$-algebras of $X$ contain it, and by \textit{biggest}, we mean that all other $\sigma$-algebras of $X$ are contained in it.
\end{remark}

\begin{theorem}[Intersections of $\sigma$-algebras are $\sigma$-algebras]
    Let $X$ be a set, and let $(\mathcal{A}_i)_{i \in I}$ be a (potentially uncountable) family of $\sigma$-algebras of $X$. Then $\bigcap_{i \in I} \mathcal{A}_i$ is a $\sigma$-algebra.
\end{theorem}

\begin{proof}~
    \begin{itemize}
        \item As we have $X \in \mathcal{A}_i$ for all $i \in I$, then we have $X \in \bigcap_{i \in I} \mathcal{A}_i$.
        \item If $A \in \bigcap_{i \in I} \mathcal{A}_i$, then $A \in \mathcal{A}_i$ for all $i \in I$, and therefore $A^c \in \mathcal{A}_i$ for all $i \in I$, meaning that $A^c \in \bigcap_{i \in I} \mathcal{A}_i$.
        \item Let $(A_j)_{j \in J}$ be a countable family over $\bigcap_{i \in I} \mathcal{A}_i$. This family is also over $\mathcal{A}_i$ for all $i \in I$. Therefore, $\bigcup_{j \in J} A_j \in \mathcal{A}_i$ for all $i \in I$, meaning that $\bigcup_{j \in J} A_j \in \bigcap_{i \in I} \mathcal{A}_i$.
    \end{itemize}
\end{proof}

\begin{remark}
    Unions of $\sigma$-algebras are not necessarily $\sigma$-algebras.
\end{remark}

\begin{definition}[Generated $\sigma$-algebra]
    Let $X$ be a set, and let $Y \subseteq \mathcal{P}(X)$. The $\sigma$-algebra of $X$ generated by $Y$, denoted $\sigma(Y)$, is the smallest $\sigma$-algebra of $X$ containing all the sets of $Y$. That is, $\sigma(Y)$ is defined as the only set such that:
    \begin{itemize}
        \item $\sigma(Y)$ is a $\sigma$-algebra of $X$
        \item $Y \subseteq \sigma(Y)$
        \item For all $\sigma$-algebra $\mathcal{A}$ of $X$ such that $Y \subseteq \mathcal{A}$, we have $\sigma(Y) \subseteq \mathcal{A}$.
    \end{itemize}
    The uniqueness of such $\sigma$-algebra can be proven directly: for any two sets respecting these properties, they would from the third property include each other, and would therefore be equal. The existence such $\sigma$-algebra is proven in the next theorem.
\end{definition}

\begin{theorem}[Characteristic property of generated $\sigma$-algebras]
    Let $X$ be a set, let $Y \subseteq \mathcal{P}(X)$, and let $Z = \{\mathcal{A} \mid \text{$Y \subseteq \mathcal{A}$ and $\mathcal{A}$ is a $\sigma$-algebra of $X$}\}$. Then we have:
        $$\sigma(Y) = \bigcap_{\mathcal{A} \in Z} \mathcal{A}$$
\end{theorem}

\begin{proof}
		Firstly, $\bigcap_{\mathcal{A} \in Z} \mathcal{A}$ is an intersection of $\sigma$-algebras of $X$, and is therefore a $\sigma$-algebra of $X$. Secondly, as $Y \subseteq \mathcal{A}$ for all $\mathcal{A} \in Z$, we have that $Y \subseteq \bigcap_{\mathcal{A} \in Z} \mathcal{A}$. Thirdly, for all $\sigma$-algebra $\mathcal{A}'$ of $X$ such that $Y \subseteq \mathcal{A}'$, we have $\mathcal{A}' \in Z$, and therefore $\bigcap_{\mathcal{A} \in Z} \mathcal{A} \subseteq \mathcal{A}'$. Therefore, $\bigcap_{\mathcal{A} \in Z} \mathcal{A}$ respects all the three properties of the definition of $\sigma(Y)$, meaning that $\sigma(Y) = \bigcap_{\mathcal{A} \in Z} \mathcal{A}$.
\end{proof}

\section{Measure spaces and measures}

\begin{definition}[Measure spaces and measures]
    Let $(X, \mathcal{A})$ be a measurable space. A measure space is a tuple $(X, \mathcal{A}, \mu)$, where $\mu$ is a \textit{measure} over $(X, \mathcal{A})$. That is, $\mu$ is a function of type $\mathcal{A} \rightarrow [0, \infty]$ such that:
    \begin{itemize}
        \item $\mu(\varnothing) = 0$
        \item For all countable family $(A_i)_{i \in \mathbb{N}}$ of disjoint measurable sets of $\mathcal{A}$, we have:
            $$\mu(\bigcup_{i \in \mathbb{N}} A_i) = \sum_{i \in \mathbb{N}} \mu(A_i)$$
    \end{itemize}
\end{definition}

\begin{remark}
    Do not be mistaken between measurable spaces and measure spaces. A measure space is a measurable space with a measure.
\end{remark}

\begin{definition}[Negligible set]
    Let $(X, \mathcal{A}, \mu)$ be a measure space. For all $A \in \mathcal{A}$, we say that $A$ is \textit{negligible} when $\mu(A) = 0$. For instance, the empty set is always negligible.
\end{definition}

\begin{definition}[Total mass]
    Let $(X, \mathcal{A}, \mu)$ be a measure space. The total mass of $\mu$ is $\mu(X)$.
\end{definition}

%\begin{definition}[Increasing and decreasing families of sets]
%    Let $(A_i)_{i \in I}$ be a family of sets. We say that $(A_i)_{i \in I}$ is increasing %when:
%         $$\forall i \in I, A_i \subseteq A_{i+1}$$
%    Similarly, we say that $(A_i)_{i \in I}$ is decreasing when:
%         $$\forall i \in I, A_i \supseteq A_{i+1}$$
%\end{definition}

\begin{definition}[Finiteness and $\sigma$-finiteness]
    We say that $\mu$ is finite when its total mass isn't $\infty$, and we say that $\mu$ is $\sigma$-finite when there exists a countable family $(A_i)_{i \in \mathbb{N}}$ of measurable sets such that:
    \begin{itemize}
		%\item \fbox{$(A_i)_{i \in \mathbb{N}}$ is increasing:}
		%    $$\forall i \in \mathbb{N}, A_i \subseteq A_{i+1}$$
        \item $(A_i)_{i \in \mathbb{N}}$ covers $X$:
            $$X = \bigcup_{i \in \mathbb{N}} A_i$$
        \item $(A_i)_{i \in \mathbb{N}}$ has no element of infinite mass:
            $$\forall i \in \mathbb{N}, \mu(A_i) \neq \infty$$
    \end{itemize}
\end{definition}

\begin{remark}
    Finiteness implies $\sigma$-finiteness, but $\sigma$-finiteness doesn't necessarily imply finiteness.
\end{remark}

\begin{definition}[Dirac measure]
    Let $(X, \mathcal{A})$ be a measurable space, and let $x \in X$. The \textit{Dirac measure at $x$} is defined as:
        $$\delta_x : \mathcal{A} \rightarrow [0, \infty]$$
        $$A \mapsto \begin{cases} 1 & \tif x \in A\\ 0 & \tif x \notin A\end{cases}$$
    Let's prove that the Dirac measure is indeed a measure. Firstly, as $x \notin \varnothing$, then $\delta_x(\varnothing) = 0$. Secondly, let $(A_i)_{i \in \mathbb{N}}$ be a countable family of disjoint measurable sets. We have two cases:
    \begin{itemize}
        \item If $x \in \bigcup_{i \in \mathbb{N}} A_i$, then, as the $A_i$ are disjoint, there exists a unique $j \in \mathbb{N}$ such that $x \in A_j$, and for all other $i \in \mathbb{N} \setminus \{j\}$, $x \notin A_i$. Therefore:
            $$\sum_{i \in \mathbb{N}} \delta_x(A_i) = \delta_x(A_j) + \sum_{i \in \mathbb{N} \setminus \{j\}} \delta_x(A_i) = 1 + \sum_{i \in \mathbb{N} \setminus \{j\}} 0 = 1 = \delta_x(\bigcup_{i \in \mathbb{N}} A_i)$$
        \item If $x \notin \bigcup_{i \in \mathbb{N}} A_i$, then for all $i \in \mathbb{N}$, $x \notin A_i$, and therefore:
        $$\sum_{i \in \mathbb{N}} \delta_x(A_i) = \sum_{i \in \mathbb{N}} 0 = 0 = \delta_x(\bigcup_{i \in \mathbb{N}} A_i)$$
    \end{itemize}
\end{definition}

\begin{theorem}[Positive linear combinations of measures are measures] \label{thm:pos_lin_comb_measures}
    Let $(X, \mathcal{A})$ be a measurable space, let $(\mu_i)_{i \in \mathbb{N}}$ be a countable family of measures over $(X, \mathcal{A})$, and let $(a_i)_{i \in \mathbb{N}}$ be a countable family of elements of $\mathbb{R}_+$. Then $\mu = \sum_{i \in \mathbb{N}} a_i \mu_i$ is a measure over $(X, \mathcal{A})$.
\end{theorem}

\begin{proof}~
    \begin{itemize}
        \item $\mu(\varnothing) = \left(\sum_{i \in \mathbb{N}} a_i \mu_i\right)(\varnothing) = \sum_{i \in \mathbb{N}} a_i \mu_i(\varnothing) = \sum_{i \in \mathbb{N}} 0 = 0$
        \item Let $(A_j)_{j \in \mathbb{N}}$ be a countable family of distinct measurable sets of $\mathcal{A}$. Then we have:
        \begin{align*}
            \mu(\bigcup_{j \in \mathbb{N}} A_j) &= \left(\sum_{i \in \mathbb{N}} a_i \mu_i\right)(\bigcup_{j \in \mathbb{N}} A_j)\\
            &= \sum_{i \in \mathbb{N}} a_i \mu_i(\bigcup_{j \in \mathbb{N}} A_j)\\
            &= \sum_{i \in \mathbb{N}} a_i \sum_{j \in \mathbb{N}} \mu_i(A_j)\\
            &= \sum_{i \in \mathbb{N}} \sum_{j \in \mathbb{N}} a_i \mu_i(A_j)\\
            &= \sum_{j \in \mathbb{N}} \sum_{i \in \mathbb{N}} a_i \mu_i(A_j)\\
            &= \sum_{j \in \mathbb{N}} \left(\sum_{i \in \mathbb{N}} a_i \mu_i\right)(A_j)\\
            &= \sum_{j \in \mathbb{N}} \mu(A_j)
        \end{align*}
    \end{itemize}
\end{proof}

\begin{definition}[Discrete measures]
    Let $(X, \mathcal{A})$ be a measurable space. A \textit{discrete measure} is a positive linear combination of Dirac measures (which from theorem (\ref{thm:pos_lin_comb_measures}) is a measure). That is, let $(a_i)_{i \in \mathbb{N}}$ be a countable family of elements of $\mathbb{R}_+$, and let $(x_i)_{i \in \mathbb{N}}$ be a countable family of elements of $X$. Then $\sum_{i \in \mathbb{N}} a_i \delta_{x_i}$ is a discrete measure.
\end{definition}

\begin{definition}[Counting measure]
    Let $(X, \mathcal{A})$ be a measurable space. The counting measure is defined as:
        $$\chi(A) = \begin{cases} Card(A) & \tif A \text{ is countable}\\ \infty & \tif A \text{ is uncountable}\end{cases} = \begin{cases}Card(A) & \tif A \text{ is finite}\\ \infty & \tif A \text{ is infinite}\end{cases}$$
		If $X$ is countable, then $\chi$ is a discrete measure since for all $A \in \mathcal{A}$, we have $\chi(A) = Card(A) = \sum_{x \in A} 1 = \sum_{x \in A} \delta_x(A) = \left(\sum_{x \in A} \delta_x\right)(A)$. If $X$ is uncountable, then $\chi$ still is a measure, because $\chi(\varnothing)=0$ and that, for all countable family $(A_i)_{i \in \mathbb{N}}$ of distinct measurable sets, we have $\chi(\bigcup_{i\in\mathbb{N}} A_i) = \infty = \sum_{i\in\mathbb{N}} \chi(A_i)$.
\end{definition}

%\begin{theorem}
%    Let $(X, \mathcal{A}, \mu)$ be a measure space. Then the following four properties are true:
%    \begin{itemize}
%        \item Monotonicity:
%            $$\forall A, B \in \mathcal{A}, A \subseteq B \implies \mu{A} \leq \mu{B}$$
%        \item Subadditivity: Let $(A_i)_{i \in \mathbb{N}}$ be a countable family of (not necessarily distinct) measurable sets of $\mathcal{A}$. Then we have:
%            $$\mu(\bigcup_{i \in \mathbb{N}} A_i) \leq \sum_{i \in \mathbb{N}} \mu(A_i)$$
%        \item Let $(A_i)_{i \in \mathbb{N}}$ be an increasing countable family of measurable sets of $\mathcal{A}$. Then we have:
%            $$\mu(\sum_{i \in \mathbb{N}} A_i) = \lim_{i \rightarrow \infty} \mu(A_i)$$
%        \item Same but for decreasing sequences
%    \end{itemize}
    %https://proofwiki.org/wiki/Measure_of_Limit_of_Increasing_Sequence_of_Measurable_Sets
%\end{theorem}

\section{Borel $\sigma$-algebra and Lebesgue measure}

\begin{definition}[Borel $\sigma$-algebra]
		Let $(E, T)$ be a topological space. We define the Borel $\sigma$-algebra of $(E, T)$, denoted $\mathcal{B}(E, T)$, as the $\sigma$-algebra generated by $T$. That is, $\mathcal{B}(E, T)$ is the smallest $\sigma$-algebra of $E$ which contains all the open sets of $E$. When there is no confusion about which topology is used, we will write $\mathcal{B}(E)$ instead of $\mathcal{B}(E, T)$. 
\end{definition}

\begin{definition}[Rectangular cuboid]
	We say that $C \subseteq \mathbb{R}^n$ is a rectangular cuboid when it is of the form $C = [a_1, b_1] \times \dots \times [a_n, b_n]$. When introducing a rectangular cuboid of this form, we will always assume that $a_i \leq b_i$ for all $i \in \{1, \dots, n\}$.
\end{definition}

\begin{theorem}[Rectangular cuboids are borel sets]
	For all rectangular cuboid $C = [a_1, b_1] \times \dots \times [a_n, b_n]$, we have that $C \in \mathcal{B}(\mathbb{R}^n)$.
\end{theorem}

\begin{proof}
	\fbox{Requires the notion of all norms being equivalent.}
\end{proof}

\begin{theorem}[Borel $\sigma$-algebra is generated by rectangular cuboids]
		\fbox{TODO}
\end{theorem}

\begin{definition}[Lebesgue Measure]
    Let's consider the measurable space $(\mathbb{R}^n, \mathcal{B}(\mathbb{R}^n))$. We define the Lebesgue measure $\lambda$ over $(\mathbb{R}^n, \mathcal{B}(\mathbb{R}^n))$ as the only measure such that, for all rectangular cuboid $C = [a_1, b_1] \times \dots \times [a_n, b_n] \in \mathcal{B}(\mathbb{R}^n)$, we have:
        $$\lambda(C) = \prod_{i=1}^n (b_i - a_i)$$
    \fbox{Let's now prove the existence and uniqueness of the Lebesgue measure.}
\end{definition}

\section{Measurable mapping and function}

\begin{definition}[Measurable mapping and function]
		Let $(X, \mathcal{A})$ and $(Y, \mathcal{B})$ be measurable spaces, and let $f : X \rightarrow Y$. We say that $f$ is a \textit{measurable mapping} when, for all $B \in \mathcal{B}$, we have that $f^{-1}(B) \in \mathcal{A}$. When $Y \subseteq [-\infty, \infty]$, we say that $f$ is a \textit{measurable function}. We denote by $\mathcal{M}(X, Y)$ the set of measurable mappings from $X$ to $Y$.
\end{definition}

\begin{theorem}[Composition of measurable mappings are measurable] \label{thm:compose-measurable}
		Let $(X, \mathcal{A})$, $(Y, \mathcal{B})$, and $(Z, \mathcal{C})$ be measurable spaces, and let $f \in \mathcal{M}(X, Y)$ and $g \in \mathcal{M}(Y, Z)$. Then, $g \circ f \in \mathcal{M}(X, Z)$.
\end{theorem}

\begin{proof}
		For all $C \in \mathcal{C}$, since $g$ is measurable, we have $g^{-1}(C) \in \mathcal{B}$, and since $f$ is measurable, we have $(g \circ f)^{-1}(C) = \{x \in X \mid g(f(x)) \in C\} = \{x \in X \mid f(x) \in g^{-1}(C)\} = f^{-1}(g^{-1}(C)) \in \mathcal{A}$, which proves that $g \circ f$ is measurable.
\end{proof}

\begin{definition}[Image $\sigma$-algebra] %Thanks Benjamin Charlier, proposition 2.11
		Let $(X, \mathcal{A})$ be a measurable space, let $Y$ be a set, and let $f : X \rightarrow Y$. We define the \textit{image $\sigma$-algebra} of $\mathcal{A}$ with respect to $f$ as:
				$$f_*(\mathcal{A}) = \{B \subseteq Y \mid f^{-1}(B) \in \mathcal{A}\}$$
		It is indeed a $\sigma$-algebra of $Y$ because:
		\begin{itemize}
				\item $Y \subseteq Y$ and $f^{-1}(Y) = X \in \mathcal{A}$, therefore $Y \in f_*(\mathcal{A})$
				\item Let $B \in f_*(\mathcal{A})$. Then $f^{-1}(B) \in \mathcal{A}$, and therefore $(f^{-1}(B))^c \in \mathcal{A}$, and since $(f^{-1}(B))^c = \{x \in X \mid f(x) \in B\}^c = \{x \in X \mid f(x) \in B^c\} = f^{-1}(B^c)$, then $f^{-1}(B^c) \in \mathcal{A}$, and as we also have $B^c \subseteq Y$, then we have $B^c \in f_*(\mathcal{A})$.
				\item Let $(B_n)_{n \in \mathbb{N}}$ be a countable family such that $B_n \in f_*(\mathcal{A})$ for all $n \in \mathbb{N}$. Then, as $f^{-1}(B_n) \in \mathcal{A}$ for all $n \in \mathbb{N}$, we have $\bigcup_{n \in \mathbb{N}} f^{-1}(B_n) \in \mathcal{A}$, and since $\bigcup_{n \in \mathbb{N}} f^{-1}(B_n) = f^{-1}(\bigcup_{n \in \mathbb{N}} B_n)$, then $f^{-1}(\bigcup_{n \in \mathbb{N}} B_n) \in \mathcal{A}$. Furthermore, as $\bigcup_{n \in \mathbb{N}} B_n \subseteq Y$, then $\bigcup_{n \in \mathbb{N}} B_n \in f_*(\mathcal{A})$.
		\end{itemize}
\end{definition}

\begin{theorem}[A mapping is measurable iff it is measurable on a generating $\sigma$-algebra] \label{thm:measurable-iff-measurable-on-generating-sigma-algebra}%Thanks to Benjamin Charlier, proposition 2.13
		Let $(X, \mathcal{A})$ and $(Y, \mathcal{B})$ be sets, and let $\mathcal{C} \subseteq \mathcal{P}(Y)$ such that $\sigma(\mathcal{C}) = \mathcal{B}$. Then, for all $f : X \rightarrow Y$, we have that $f \in \mathcal{M}(X, Y)$ if and only if, for all $C \in \mathcal{C}$, $f^{-1}(C) \in \mathcal{A}$.
\end{theorem}

\begin{proof}~
		\begin{itemize}
				\item If $f \in \mathcal{M}(X, Y)$, then for all $C \in \mathcal{C}$, we have $C \in \mathcal{C} \subseteq \sigma(\mathcal{C}) = \mathcal{B}$, and so $C \in \mathcal{B}$, and since $f$ is measurable, then $f^{-1}(C) \in \mathcal{A}$.
				\item If for all $C \in \mathcal{C}$, $f^{-1}(C) \in \mathcal{A}$, then $\mathcal{C} \subseteq \{C \subseteq Y \mid f^{-1}(C) \in \mathcal{A}\} = f_*(\mathcal{A})$. Since $f_*(\mathcal{A})$ is a $\sigma$-algebra which contains $\mathcal{C}$, then from the definition of generated $\sigma$-algebra, we have that $\sigma(\mathcal{C}) \subseteq f_*(\mathcal{A})$. Therefore, for all $B \in \mathcal{B}$, we have $B \in \mathcal{B} = \sigma(\mathcal{C}) \subseteq f_*(\mathcal{A})$, and therefore $f^{-1}(B) \in \mathcal{A}$, proving that $f \in \mathcal{M}(X, Y)$.
		\end{itemize}
\end{proof}

\begin{theorem}[Continuous functions are measurable] \label{thm:continuous-measurable} %Benjamin Charlier (proposition 2.14)
		Let $f : \mathbb{R}^m \rightarrow \mathbb{R}^n$ be a continuous function \fbox{(TO DEFINE)}. Then, $f \in \mathcal{M}(\mathbb{R}^m, \mathbb{R}^n)$.
\end{theorem}

\begin{proof}
		Since, by definition, the Borel $\sigma$-algebra $\mathcal{B}(\mathbb{R}^n)$ is generated by the set $T_{\mathbb{R}^n}$ of opens of $\mathbb{R}^n$, we only need to prove from theorem (\ref{thm:measurable-iff-measurable-on-generating-sigma-algebra}) that, for all open $O \in T_{\mathbb{R}^n}$, we have that $f^{-1}(O) \in \mathcal{B}(\mathbb{R}^m)$. Since $f$ is continuous, then $f^{-1}(O) \in T_{\mathbb{R}^m} \subseteq \mathcal{B}(\mathbb{R}^m)$, proving that $f$ is measurable.
\end{proof}

\begin{theorem}[Finite linear combinations of measurable functions are measurable] \label{thm:linear-combination-measurable} %Benjamin Charlier (proposition 2.16)
		Let $(X, \mathcal{A})$ be a measurable space, let $f_1, \dots, f_n \in \mathcal{M}(X, \mathbb{R})$ be measurable functions, and let $a_1, \dots, a_n \in \mathbb{R}$. Then, $\sum_{i=1}^n a_i f_i$ is measurable.
\end{theorem}

\begin{proof}
		Let's remark that $\sum_{i=1}^n f_i = (s \circ m \circ F)$, where $s(x_1, \dots, x_n) = \sum_{i=1}^n x_i$, where $m(x_1, \dots, x_n) = (a_1 x_1, \dots, a_n x_n)$, and where $F(x) = (f_1(x), \dots, f_n(x))$. Therefore, to prove that $\sum_{i=1}^n f_i$ is measurable, we only need to prove from theorem (\ref{thm:compose-measurable}) that $s$, $m$, and $F$ are measurable:
		\begin{itemize}
				\item Since \fbox{$s$ is a continuous function of $\mathbb{R}^n \rightarrow \mathbb{R}^n$}, then from theorem (\ref{thm:continuous-measurable}), it is measurable.
				\item Similarly, since \fbox{$m$ is a continuous function of $\mathbb{R}^n \rightarrow \mathbb{R}^n$}, then it is measurable.
				\item Let's prove that $F(x) = (f_1(x), \dots, f_n(x))$ is measurable (i.e. $F \in \mathcal{M}(X, \mathbb{R}^n)$. As the set of rectangular cuboids is a generating set of the Borel $\sigma$-algebra $\mathcal{B}(\mathbb{R}^n)$, then from theorem (\ref{thm:measurable-iff-measurable-on-generating-sigma-algebra}), we only need to prove that, for all rectangular cuboid $C = [a_1, b_1] \times \dots [a_n, b_n]$, $F^{-1}(C) \in \mathcal{A}$:
				\begin{align*}
						F^{-1}(C) &= \{x \in X \mid F(x) \in C\}\\
						  &= \{x \in X \mid (f_1(x), \dots, f_n(x)) \in [a_1, b_1] \times \dots [a_n, b_n]\}\\
						  &= \bigcap_{i=1}^n \{x \in X \mid f_i(x) \in [a_i, b_i]\}\\
						  &= \bigcap_{i=1}^n f_i^{-1}([a_i, b_i])
				\end{align*}
				As each $[a_i, b_i]$ is measurable, and that each $f_i$ is measurable, then each $f^{-1}([a_i, b_i])$ is measurable. Therefore, $F^{-1}(C)$ is a finite intersection of measurable sets, which is measurable, proving that $F$ is measurable.
		\end{itemize}
\end{proof}

\begin{theorem}[Finite products of measurable functions are measurable] \label{thm:product-measurable-functions}
		Let $(X, \mathcal{A})$ be a measurable space, and let $f_1, \dots, f_n \in \mathcal{M}(X, [-\infty, \infty])$ be measurable functions. Then, $\prod_{i=1}^n f_i$ is measurable. Note that, by definition of the augmented real numbers, $0 \cdot \infty = 0 \cdot -\infty = 0$.
\end{theorem}

\begin{proof}
		Just as in theorem (\ref{thm:linear-combination-measurable}), we remark that $\prod_{i=1}^n f_i = (p \circ F)$, where $p(x_1, \dots, x_n) = \prod_{i=1}^n x_i$ \fbox{is continuous} and therefore measurable, and where $F(x_1, \dots, x_n) = (f_1(x_1), \dots, f_n(x_n))$ has already been proven to be measurable. Therefore, $\prod_{i=1}^n f_i$ is measurable.
\end{proof}

\begin{theorem}[Supremum and infremum of families of measurable functions are measurable] %Benjamin Charlier (proposition 2.17)
		Let $(X, \mathcal{A})$ be a measurable space, and let $(f_n)_{n \in \mathbb{N}}$ be a countable family of measurable functions of $\mathcal{M}(X, [-\infty, \infty])$. Then, $\inf_{n \in \mathbb{N}}(f_n) \in \mathcal{M}(X, [-\infty, \infty])$ and $\sup_{n \in \mathbb{N}}(f_n) \in \mathcal{M}(X, [-\infty, \infty])$.
\end{theorem}

\begin{proof}
		
\end{proof}

\begin{theorem}[Pointwise limits of measurable functions are measurable] \label{thm:limit-measurable-is-measurable}
		Let $(X, \mathcal{A})$ be a measurable space, and let $(f_n)_{n \in \mathbb{N}}$ be a countable family of measurable functions of $\mathcal{M}(X, [-\infty, \infty])$. Then, if $(f_n)_{n \in \mathbb{N}}$ converges pointwise to a function $f$, then $f$ is measurable.
\end{theorem}

\begin{proof}
		
\end{proof}

\section{Integration}

\begin{definition}[Simple function] %Fonction étagée
		Let $(X, \mathcal{A})$ be a measurable space, and let $f : X \rightarrow \mathbb{R}$ be a function. We say that $f$ is \textit{simple} when there exists a finite number of measurable sets $(A_1, \dots, A_n)$ of $X$ and coefficients $(c_1, \dots, c_n) \in \mathbb{R}^n$ such that:
				$$f : X \rightarrow \mathbb{R}$$
				$$x \mapsto \sum_{i=1}^n c_i \mathbbm{1}_{A_i}(x)$$
				where $\mathbbm{1}_{A_i}(x)$ is the function which equals 1 if $x \in A$, and otherwise 0. Simple functions therefore take only finitely many values. We denote by $\mathcal{E}(X)$ the set of simple functions, and by $\mathcal{E}^+(X)$ the set of positive simple functions.
\end{definition}

\begin{remark}
		Without loss of generality, we can assume that the set $(A_1, \dots, A_n)$ covers $X$, because we can always rewrite $f$ as $f(x) = \sum_{i=1}^{n+1} c_i \mathbbm{1}_{A_i}(x)$ with $A_{n+1} = X$ and $c_{i+1} = 0$. We can also without loss of generality assume that $(A_1, \dots, A_n)$ is a partition of $X$. Furthermore, we can also assume without loss of generality that each $c_i$ are distinct.
\end{remark}

\begin{theorem}[Characteristic property of simple functions] \label{thm:simple-function-charac}
		For measurable spaces $(X, \mathcal{A})$ and $(\mathbb{R}, \mathcal{B}(\mathbb{R}))$, simple functions $f \in \mathcal{E}(X)$ are exactly the finite measurable functions $f \in \mathcal{M}(X, \mathbb{R})$ which take only finitely many values.
\end{theorem}

\begin{proof}~
		\begin{itemize}
				\item If $f \in \mathcal{E}(X)$ is a simple function of the form $f(x) = \sum_{i=1}^n c_i \mathbbm{1}_{A_i}(x)$ (where we assume without loss of generality that $(A_1, \dots, A_n)$ is a finite partition of $X$), then for any Borel set $B \in \mathcal{B}(R)$, we have that:
						$$f^{-1}(B) = \{x \in X \mid f(x) \in B\} = \bigcup_{i=1}^n \{x \in A_i \mid f(x) \in B\} = \bigcup_{i=1}^n \{x \in A_i \mid c_i \in B\} = \bigcup_{i|c_i \in B} A_i$$
				where the last union is over every $i \in 1, \dots, n$ such that $c_i \in B$. As $f^{-1}(B)$ is equal to a finite union of measurable sets, it is itself measurable, proving that $f \in \mathcal{M}(X, \mathbb{R})$. Furthermore, $f$ is finite, and we have already seen that $f$ also takes only finitely many values.
		\item If $f \in \mathcal{M}(X, \mathbb{R})$ is a finite measurable function which takes only finitely many values $(y_1, \dots, y_n)$, with each $y_i$ being distinct and finite, then we can prove that $(A_1, \dots, A_n) = (f^{-1}(\{y_1\}), \dots, f^{-1}(\{y_n\}))$ is a finite partition of $X$, where each $A_i$ is measurable:
				\begin{itemize}
						\item Since $f$ is measurable, and that each singleton $\{y_i\}$ is a Borel set (i.e. $\{y_i\} \in \mathcal{B}(\mathbb{R})$), then each $A_i = f^{-1}(\{y_i\})$ is measurable (i.e. $A_i \in \mathcal{A}$).
						\item If there were to exist $x \in A_i \cap A_j$, we would have $f(x) = y_i$ and $f(x) = y_j$, which is impossible because we assumed that all $y_i$ were distinct. Therefore:
								$$\forall i, j \in \{1, \dots, n\}, A_i \cap A_j = \varnothing$$
						\item For each $x \in X$, there exists $i$ such that $f(x) = y_i$, and therefore $x \in f^{-1}(\{y_i\}) = A_i \subseteq \bigcup_{i=1}^n A_i$, meaning that $X \subseteq \bigcup_{i=1}^n A_i$. We also have $\bigcup_{i=1}^n A_i \subseteq X$ since each $A_i$ is a subset of $X$. Therefore, we have:
								$$\bigcup_{i=1}^n A_i = X$$
				\end{itemize}
				As $(A_1, \dots, A_n)$ is a finite partition of $X$, with each $A_i$ being measurable, and that each $y_i$ is finite, then $x \mapsto \sum_{i=1}^n y_i \mathbbm{1}_{A_i}(x)$ is a simple function. For each $x \in X$, there exists exactly one $j \in 1, \dots, n$ such that $x \in A_j$, and therefore $\sum_{i=1}^n y_i \mathbbm{1}_{A_i}(x) = y_j = f(x)$. Therefore, $f(x) = \sum_{i=1}^n y_i \mathbbm{1}_{A_i}(x)$, meaning that $f$ is a simple function.
		\end{itemize}
\end{proof}

\begin{remark}
		From theorem (\ref{thm:simple-function-charac}), it follows directly that we can use theorems (\ref{thm:linear-combination-measurable}) and (\ref{thm:product-measurable-functions}) to deduce respectively that finite linear combinations of simple functions and finite products of simple functions are simple.
\end{remark}

\begin{theorem}[Positive measurable functions are the pointwise limit of an ascending family of positive simple functions] \label{thm:pointwise-simple} %Thanks Benjamin Charlier (proposition 3.2)
		Let $(X, \mathcal{A})$ be a measurable space and let $f \in \mathcal{M}(X, [0, \infty])$ be a positive measurable function. Then, there is a countable ascending family $(f_n)_{n \in \mathbb{N}}$ of positive simple functions such that for all $x \in X$, $\lim_{n \rightarrow \infty} f_n(x) = f(x)$. Note that this limit is indeed defined in $[0, \infty]$ because $(f_n(x))_{i \in \mathbb{N}}$ is ascending.
\end{theorem}

\begin{proof}
		Let's consider the following countable family, defined for all $n \in \mathbb{N}$ and $x \in X$ as:
		\begin{align*}
				f_n(x) & \coloneq n\mathbbm{1}_{f^{-1}([n, \infty[)} + \sum_{i=0}^{n2^n - 1} \frac{i}{2^n}\mathbbm{1}_{A_i^{(n)}} & A_i^{(n)} &\coloneq f^{-1}(I_i^{(n)}) & I_i^{(n)} &\coloneq [\frac{i}{2^n}, \frac{i+1}{2^n}[
		\end{align*}
		We will, in three points, prove that each $f_n$ is a positive simple function, find a formula for $(f_n(x))_{n \in \mathbb{N}}$, and deduce that $(f_n)_{n \in \mathbb{N}}$ is an ascending family whose pointwise limit is $f$:
		\begin{itemize}
				\item Let $n \in \mathbb{N}$. For all $i \leq n2^n - 1$, $I_i^{(n)} \in \mathcal{B}(\mathbb{R})$, and as $f$ is measurable, we therefore have that $A_i^{(n)} = f^{-1}(I_i^{(n)}) \in \mathcal{A}$. Similarly, $[n, \infty[ \in \mathcal{B}(\mathbb{R})$ and therefore $f^{-1}([n, \infty[) \in \mathcal{A}$. Therefore, $f_n$ is indeed a positive simple function.	
				\item Let $x \in X$.
				\begin{itemize}
						\item If $n \leq f(x)$, then $f(x) \in [n, \infty[$, and as $I_0^{(n)}, \dots, I_{n2^n - 1}^{(n)}, [n, \infty[$ are disjoint, then $[n, \infty[$ is the only interval among them which contains $f(x)$. Therefore, the only interval which contains $x$ among $f^{-1}(I_0^{(n)}), \dots, f^{-1}(I_{n2^n - 1}^{(n)})$ and $f^{-1}([n, \infty[)$ is $f^{-1}([n, \infty[)$. Therefore, the value that the function $f_n$ takes at $x$ is:
								$$f_n(x) = n\mathbbm{1}_{f^{-1}([n, \infty[)} + \sum_{i=0}^{n2^n - 1} \frac{i}{2^n}\mathbbm{1}_{A_i^{(n)}} = n$$
						\item If $n > f(x)$, then let $i = \lfloor f(x) 2^n \rfloor$. We have that $0 \leq i = \lfloor f(x)2^n \rfloor \leq f(x)2^n < n2^n$, meaning that $0 \leq i \leq n2^n - 1$, and therefore that $I_i{(n)}$ exists. Furthermore, we have $\frac{i}{2^n} = \frac{\lfloor f(x) 2^n\rfloor}{2^n} \leq \frac{f(x)2^n}{2^n} = f(x) = \frac{f(x)2^n}{2^n} < \frac{\lfloor f(x)2^n \rfloor + 1}{2^n} = \frac{i + 1}{2^n}$, meaning that $f(x) \in [\frac{i}{2^n}, \frac{i + 1}{2^n}[ = I_i^{(n)}$. Note that, as $I_0^{(n)}, \dots, I_{n2^n - 1}^{(n)}, [n, \infty[$ are disjoint, then $I_i^{(n)}$ is the only interval among them which contains $f(x)$. Therefore, the only interval which contains $x$ among $f^{-1}(I_0^{(n)}), \dots, f^{-1}(I_{n2^n - 1}^{(n)})$ and $f^{-1}([n, \infty[)$ is $f^{-1}(I_i^{(n)})$. Therefore, the value that the function $f_n$ takes at $x$ is:
								$$f_n(x) = n\mathbbm{1}_{f^{-1}([n, \infty[)} + \sum_{j=0}^{n2^n - 1} \frac{j}{2^n}\mathbbm{1}_{A_j^{(n)}} = \frac{i}{2^n} = \frac{\lfloor f(x)2^n \rfloor}{2^n}$$
				\end{itemize}
				Therefore, the general formula for $(f_n(x))_{n \in \mathbb{N}}$ is:
				$$f_n(x) = \begin{cases} n & \tif n \leq f(x) \\ \frac{\lfloor f(x)2^n \rfloor}{2^n} & \tif n > f(x)\end{cases}$$
				\item Let $x \in X$, and let's prove that the above formula corresponds to an ascending family. Let $n \in \mathbb{N}$.
				\begin{itemize}
						\item If $n < n + 1 \leq f(x)$, then $f_n(x) = n < n + 1 = f_{n + 1}(x)$
						\item If $f(x) < n < n + 1$, then $f_n(x) = \frac{\lfloor f(x)2^n \rfloor}{2^n} = \frac{\lfloor f(x)2^n \rfloor \cdot 2}{2^{n+1}} \leq \frac{\lfloor f(x)2^n \cdot 2 \rfloor}{2^{n+1}} = \frac{\lfloor f(x)2^{n+1} \rfloor}{2^{n+1}} = f_{n+1}(x)$
						\item If $n \leq f(x) < n+1$, then $f_n(x) = n \leq \lfloor f(x) \rfloor = \frac{\lfloor f(x) \rfloor 2^{n+1}}{2^{n+1}} \leq \frac{\lfloor f(x) 2^{n+1} \rfloor}{2^{n+1}} = f_{n+1}(x)$
				\end{itemize}
				Therefore, $(f_n(x))_{n \in \mathbb{N}}$ is ascending, meaning that $(f_n)_{n \in \mathbb{N}}$ is ascending. Furthermore:
				\begin{itemize}
						\item If $f(x) < \infty$, then $\lim_{n \rightarrow \infty} f_n(x) = \lim_{n \rightarrow \infty} \frac{\lfloor f(x)2^n \rfloor}{2^n} = f(x)$
						\item If $f(x) = \infty$, then $\lim_{n \rightarrow \infty} f_n(x) = \lim_{n \rightarrow \infty} n = \infty = f(x)$
				\end{itemize}
				And therefore, the pointwise limit of $(f_n)_{n \in \mathbb{N}}$ is $f$.
		\end{itemize} 
\end{proof}

\begin{remark}
		The reciprocal of theorem (\ref{thm:pointwise-simple}) is true, but we will neither prove it nor use it here.
\end{remark}

\begin{definition}[Integral of a positive simple function]
		Let $(X, \mathcal{A}, \mu)$ be a measure space, and let $f(x) = \sum_{i=1}^n c_i \mathbbm{1}_{A_i}(x)$ be a \textit{positive} simple function. Then, we define the integral of $f$ according to the measure $\mu$ as:
				$$\int_X f \dd \mu = \sum_{i=1}^n c_i \mu(A_i)$$
\end{definition}

\begin{remark}
		The integral of a positive simple function may be infinite.
\end{remark}

\begin{theorem}[Integrals of positive simple functions are linear]
		Let $(X, \mathcal{A}, \mu)$ be a measure space, let $f_1, \dots, f_n \in \mathcal{E}^+(X)$ be positive simple functions, and let $a_1, \dots, a_n \in \mathbb{R}$. Then:
				$$\int_X \sum_{i=1}^n a_i f_i \dd \mu = \sum_{i=1}^n a_i \int_X f_i \dd \mu$$
\end{theorem}
		
\begin{proof}
		Without loss of generality, we can assume that each $f_i$ uses the same measurable sets $(A_1, \dots, A_m)$. Then, each $f_i$ has its own coefficients $c^{(i)}_1, \dots, c^{(i)}_m \in \mathbb{R}$, and we have:
		\begin{align*}
				\sum_{i=1}^n a_i f_i &= \sum_{i=1}^n a_i \sum_{j=1}^m c^{(i)}_j \mathbbm{1}_{A_j}\\
									 &= \sum_{i=1}^n \sum_{j=1}^m a_i c^{(i)}_j \mathbbm{1}_{A_j}\\
									 &= \sum_{j=1}^m \sum_{i=1}^n a_i c^{(i)}_j \mathbbm{1}_{A_j}\\
									 &= \sum_{j=1}^m \left( \sum_{i=1}^n a_i c^{(i)}_j \right) \mathbbm{1}_{A_j}
		\end{align*}
		And the integral therefore is:
		\begin{align*}
				\int_X \sum_{i=1}^n a_i f_i \dd \mu &= \sum_{j=1}^m \left( \sum_{i=1}^n a_i c^{(i)}_j \right) \mu(A_j)\\
													&= \sum_{j=1}^m \sum_{i=1}^n a_i c^{(i)}_j \mu(A_j)\\
													&= \sum_{i=1}^n \sum_{j=1}^m a_i c^{(i)}_j \mu(A_j)\\
													&= \sum_{i=1}^n a_i \sum_{j=1}^m c^{(i)}_j \mu(A_j)\\
													&= \sum_{i=1}^n a_i \int_X f_i \dd \mu
		\end{align*}
\end{proof}


\begin{theorem}[Smaller positive simple functions have a smaller integral] \label{thm:smaller-simple-functions-smaller-integral}
		Let $(X, \mathcal{A}, \mu)$ be a measure space, and let $f, g \in \mathcal{E}^+(X)$. If for all $x \in X$, $f(x) \leq g(x)$, then:
				$$\int_X f \dd \mu \leq \int_X g \dd \mu$$
\end{theorem}

\begin{proof}
		Since $g - f$ is a linear combination of simple functions, it is itself a simple function. Furthermore, as for all $x \in X$, $f(x) \leq g(x)$, then $g(x) - f(x) \geq 0$, and therefore $g - f$ is a positive simple function. We therefore have:
				$$\int_X f \dd \mu \leq \int_X f \dd \mu + \int_X (g - f) \dd \mu = \int_X f + (g - f) \dd \mu = \int_X g \dd \mu$$
\end{proof}

%\begin{theorem} %Thanks Benjamin Charlier (lemma 3.6)
%		Let $(X, \mathcal{A}, \mu)$ be a measure space, let $(f_n)_{n\in\mathbb{N}}$ be a countable family of positive simple functions such that $\forall x \in X, \forall n \in \mathbb{N}, f_n(x) \leq f_{n+1}(x)$, and let $g \in \mathcal{E}^+(X)$ such that $\forall x \in X, g(x) \leq \lim_{n \rightarrow \infty} f_n(x)$. Note that these limits are indeed defined because $(f_n(x))_{n \in \mathbb{N}}$ is ascending. Then, we have that:
%				$$\int_X g \dd \mu \leq \lim_{n\rightarrow\infty} \int_X f_n \dd \mu$$
%				Note once again that this limit too is defined because $(\int_X f_n \dd \mu)_{n \in \mathbb{N}}$ is an \fbox{ascending family according to the previous theorem}
%\end{theorem}

%\begin{proof}
		
%\end{proof}

%\begin{theorem}
%		Let $(X, \mathcal{A}, \mu)$ be a measurable space, let $f \in \mathcal{M}(X, [0, \infty])$ be a positive measurable function, and let $(f_n)_{n \in \mathbb{N}}$ and $(g_n)_{n \in \mathbb{N}}$ be families of positive simple functions such that:
%		\begin{itemize}
%				\item $(f_n)_{n \in \mathbb{N}}$ and $(g_n)_{n \in \mathbb{N}}$ are ascending
%						$$\forall i \in \mathbb{N}, \forall x \in X f_i(x) \leq f_{i+1}(x) \land g_i(x) \leq g_{i+1}(x)$$
%				\item $(f_n)_{n \in \mathbb{N}}$ and $(g_n)_{n \in \mathbb{N}}$ converge pointwise to $f$:
%						$$\forall x \in X, \lim_{i \rightarrow \infty} f_i(x) = \lim_{i \rightarrow \infty} g_i(x) = f(x)$$
%				(the limits are defined from the first point)
%		\end{itemize}
%		Then, we have:
%				$$\lim_{i \rightarrow \infty} \int_X f_i \dd \mu = \lim_{i \rightarrow \infty} \int_X g_i \dd \mu$$
%\end{theorem}

\begin{notation}[Inequality on functions]
		Let $X$ be a set, and let $f, g : X \rightarrow [-\infty, \infty]$. We note $f \leq g$ to denote the pointwise inequality, that is, when $\forall x \in X, f(x) \leq g(x)$.
\end{notation}

\begin{definition}[Integral of a positive measurable function] %ProofWiki (Definition:Integral of Positive Measurable Function)
		Let $(X, \mathcal{A}, \mu)$ be a measure space. Then, for all positive measurable function $f \in \mathcal{M}(X, [0, \infty])$, we define the integral of $f$ according to the measure $\mu$ as:
				$$\int_X f \dd \mu = \sup_{g \in E_f} \left(\int_X g \dd \mu\right)$$
		where $E_f = \{g \in \mathcal{E}^+(X) \mid g \leq f\}$. Furthermore, for all $A \in \mathcal{A}$, we note:
				$$\int_A f \dd \mu = \int_X f \mathbbm{1}_A \dd \mu$$
\end{definition}

\begin{remark}
		The integral of positive measurable functions can be infinite. Furthermore, since $f \in \mathcal{M}(X, [0, \infty])$, the function $f$ can take the value $\infty$. Remember that, from theorem (\ref{thm:product-measurable-functions}), the product $f \mathbbm{1}_A$ is defined even when $f$ takes the value $\infty$ or $-\infty$, because from the definition of the extended real numbers, $0 \cdot \infty = 0 \cdot -\infty = 0$.
\end{remark}

\begin{theorem}[Smaller positive measurable functions have a smaller integral] \label{thm:smaller-positive-measurable-functions-smaller-integral}
		Let $(X, \mathcal{A}, \mu)$ be a measure space, and let $f, g \in \mathcal{M}(X, [0, \infty])$. If $f \leq g$, then:
				$$\int_X f \dd \mu \leq \int_X g \dd \mu$$
\end{theorem}

\begin{proof}
		Let $E_f = \{h \in \mathcal{E}^+(X) \mid h \leq f\}$ and $E_g = \{h \in \mathcal{E}^+(X) \mid g \leq f\}$. Since $f \leq g$, then $E_f \subseteq E_g$, and therefore:
		$$\int_X f \dd \mu = \sup_{h \in E_f} \left(\int_X h \dd \mu\right) \leq \sup_{h \in E_g} \left(\int_X h \dd \mu\right)$$
\end{proof}

\begin{theorem}[Integrating a positive measurable function on a smaller set gives a smaller integral]
		Let $(X, \mathcal{A}, \mu)$ be a measure space, and let $f \in \mathcal{M}(X, [0, \infty])$. For all measurable sets $A, B \in \mathcal{A}$, if $A \subseteq B$, then:
				$$\int_A f \dd \mu \leq \int_B f \dd \mu$$
\end{theorem}

\begin{proof}
		As $A \subseteq B$, then $\mathbbm{1}_A \leq \mathbbm{1}_B$, and therefore $f \mathbbm{1}_A \leq f \mathbbm{1}_B$. From theorem (\ref{thm:smaller-positive-measurable-functions-smaller-integral}), we deduce that $\int_X f \mathbbm{1}_A \dd \mu \leq \int_X f \mathbbm{1}_B \dd \mu$, and therefore that:
				$$\int_A f \dd \mu = \int_X f \mathbbm{1}_A \dd \mu \leq \int_X f \mathbbm{1}_B \dd \mu = \int_B f \dd \mu$$
\end{proof}

\begin{theorem}[Monotone convergence theorem / Beppo Levi Theorem] %Benjamin Charlier (theorem 3.11) and Wikipedia (Théorème de convergence monotone)
		Let $(X, \mathcal{A}, \mu)$ be a measure space, and let $(f_n)_{n \in \mathbb{N}}$ be an ascending family of positive measurable functions in $\mathcal{M}(X, [0, \infty])$. Then $(f_n)_{n \in \mathbb{N}}$ converges pointwise towards a measurable function $f$, and we have:
				$$\int_X f \dd \mu = \lim_{n \rightarrow \infty} \int_X f_n \dd \mu$$
\end{theorem}

\begin{proof}
		\fbox{Requires the proof that the limit of integrals of an ascending family of positive simple function converges to  the integral of the limit}
		\fbox{Also requires that Smaller positive measurable functions have a smaller integral}
		\fbox{Also requires that, when integrating on a subset, the integral is lower}
\end{proof}

\begin{theorem}[Integral of positive measurable functions are linear] %Benjamin Charlier (corollaire 3.12)
		\fbox{Requires the Monotone convergence theorem / Beppo Levi theorem}
\end{theorem}


\begin{definition}[Integral of a measurable function]
		Let $(X, \mathcal{A}, \mu)$ be a measure space, let $f \in \mathcal{M}(X, [-\infty, \infty])$, and let $f^+(x) = \max \{0, x\}$ and $f^-(x) = \max \{0, -f(x)\}$ be respectively the positive and negative parts of $f$, which are both positive measurable functions. We say that $f$ is \textit{integrable} according to $\mu$ if and only if we have both $\int_X f^+ \dd \mu < \infty$ and $\int_X f^- \dd \mu < \infty$. Equivalently, $f$ is integrable iff:
				$$\int_X |f| \dd \mu < \infty$$
		In that case, we define the integral of $f$ according to $\mu$ as:
				$$\int_X f \dd \mu = \int_X f^+ \dd \mu - \int_X f^- \dd \mu$$
		We denote by $L^1(X, \mathcal{A}, \mu)$ or $L^1(X)$ the set of integrable functions, and more generally, we denote by $L^n(X)$ the set of functions whose $n$-th power is integrable.
\end{definition}

%\begin{theorem}%TODO
%		Let $(X, \mathcal{A}, \mu)$ be a measure space. If $f, g \in L^1(X)$, then $f + g \in L^1(X)$.
%\end{theorem}

%\begin{proof}
		
%\end{proof}

%\begin{theorem}%TODO
%		Let $(X, \mathcal{A}, \mu)$ be a measure space. If $f, g \in L^2(X)$, then $f + g \in L^2(X)$.
%\end{theorem}

%\begin{proof}
%		$$(f + g)^2 = f^2 + 2fg + g^2$$
%		Let's focus on $fg$ using cauchy schwarz
%				$$\int |fg| \leq (\int f^2)^{1/2} + (\int g^2)^{1/2} < \infty$$
%\end{proof}

%\begin{theorem}%TODO
%		if $E[Y]<\infty$, then $E[|Y|] < \infty$ and from the tower property and jensen's inequality $E[|E[Y | X]|] \leq E[E[|Y| | X]] = E[|Y|] < \infty$, and therefore $E[Y | X]$ is $L^1$
%\end{theorem}

%\begin{theorem}%TODO
%		Suppose $E[Y^2] < \infty$. The law of total variance says:
%				$$\V{Y} = \E{\V{y \mid x}} + \V{E{y \mid x}}$$
%		Therefore:
%				$$\V{\E{Y \mid X}} \leq \V{Y}$$
%		Therefore:
%				$$\E{\E{Y \mid X}^2} - \E{Y}^2 \leq \E{Y^2} - \E{Y}^2$$
%		And so:
%				$$\E{\E{Y \mid X}^2} \leq \E{Y^2} < \infty$$
%				And therefore $\E{Y \mid X} \in L^2(\mathcal{X} \times \mathcal{Y})$ (where we define $\E{Y \mid X}$ arbitrarily for negligible sets).
%\end{theorem}

\section{Product measurable spaces and product $\sigma$-algebra}

\begin{definition}[Product measurable space and product $\sigma$-algebra] %Thanks ProofWiki (Definition:Product Sigma-Algebra) and Benjamin Charlier
		Let $(X, \mathcal{A})$ and $(Y, \mathcal{B})$ be measurable spaces. We define the product $\sigma$-algebra of $\mathcal{A}$ and $\mathcal{B}$ as the $\sigma$-algebra generated by the products of all sets of $\mathcal{A}$ and all sets of $\mathcal{B}$:
				$$\mathcal{A} \otimes \mathcal{B} \coloneq \sigma(\{A \times B \mid (A, B) \in \mathcal{A} \times \mathcal{B}\})$$
		From this, we define the \textit{product measurable space} of $(X, \mathcal{A})$ and $(Y, \mathcal{B})$ as $(X \times Y, \mathcal{A} \otimes \mathcal{B})$.
\end{definition}

\begin{definition}[Projection mappings]
		Let $X$ and $Y$ be sets. We define the \textit{projection mappings} $\pr_1 : X \times Y \rightarrow X$ and $\pr_2 : X \times Y \rightarrow Y$ as:
		\begin{align*}
				\pr_1(x, y) &= x & \pr_2(x, y) &= y
		\end{align*}
\end{definition}

\begin{theorem}[Projection mappings are measurable]
		Let $(X, \mathcal{A})$ and $(Y, \mathcal{B})$ be measurable spaces, let $(X \times Y, \mathcal{A} \otimes \mathcal{B})$ be the product measurable space. Then, the projection mappings $\pr_1(x, y) = x$ and $\pr_2(x, y) = y$ are measurable.
\end{theorem}

\begin{proof}
		For all $A \in \mathcal{A}$, we have:
				$$\pr_1^{-1}(A) = \{(x, y) \in X \times Y \mid \pr_1(x, y) \in A\} = \{(x, y) \in X \times Y \mid x \in A\} = A \times Y$$
		which belongs to $\mathcal{A} \otimes \mathcal{B}$ since $(A, Y) \in \mathcal{A} \times \mathcal{B}$, proving that $\pr_1$ is measurable. Similarly, for all $B \in \mathcal{B}$, $\pr_2^{-1}(B) = X \times B \in \mathcal{A} \otimes \mathcal{B}$, and therefore $\pr_2$ is measurable.
\end{proof}

\begin{theorem}[A mapping is measurable iff its projections are measurable] %Thanks Benjamin Charlier, proposition 4.9
		Let $(X, \mathcal{A})$, $(Y, \mathcal{B})$, and $(Z, \mathcal{C})$ be measurable spaces, and let $f : Z \rightarrow X \times Y$. Then, $f \in \mathcal{M}(Z, X \times Y)$ if and only if $\pr_1 \circ f \in \mathcal{M}(Z, X)$ and $\pr_2 \circ f \in \mathcal{M}(Z, Y)$.
\end{theorem}

\begin{proof}~
		\begin{itemize}
				\item Let $f \in \mathcal{M}(Z, X \times Y)$. Since $\pr_1 \circ f$ and $\pr_2 \circ f$ are composition of measurable mappings, then from theorem (\ref{thm:compose-measurable}), they are measurable (i.e. $\pr_1 \circ f \in \mathcal{M}(Z, X)$ and $\pr_2 \circ f \in \mathcal{M}(Z, Y)$).
				\item Let $f : Z \rightarrow X \times Y$ such that $\pr_1 \circ f \in \mathcal{M}(Z, X)$ and $\pr_2 \circ f \in \mathcal{M}(Z, Y)$. To prove that $f \in \mathcal{M}(Z, X \times Y)$, we would have to prove that for all $S \in \mathcal{A} \otimes \mathcal{B}$, $f^{-1}(S) \in \mathcal{C}$. However, theorem (\ref{thm:measurable-iff-measurable-on-generating-sigma-algebra}) tells us that it is sufficient to prove it for all $S$ belonging to a generating $\sigma$-algebra of $\mathcal{A} \otimes \mathcal{B}$. As $\mathcal{A} \otimes \mathcal{B}$ is by definition generated by $\{A \times B \mid (A, B) \in \mathcal{A} \times \mathcal{B}\}$, we just need to prove that $f^{-1}(A \times B) \in \mathcal{C}$ for all $(A, B) \in \mathcal{A} \times \mathcal{B}$. In that case, we have:
				\begin{align*}
						f^{-1}(A \times B) &= \{z \in Z \mid f(z) \in A \times B\}\\
										   &= \{z \in Z \mid ((\pr_1 \circ f)(z), (\pr_2 \circ f)(z)) \in A \times B\}\\
										   &= \{z \in Z \mid (\pr_1 \circ f)(z) \in A\} \cap \{z \in Z \mid (\pr_2 \circ f)(z) \in B\}\\
										   &= (\pr_1 \circ f)^{-1}(A) \cap (\pr_2 \circ f)^{-1}(B)
				\end{align*}
						And as $\pr_1 \circ f \in \mathcal{M}(Z, X)$ and $\pr_2 \circ f \in \mathcal{M}(Z, Y)$, then $(\pr_1 \circ f)^{-1}(A) \in \mathcal{C}$ and $(\pr_2 \circ f)^{-1}(B) \in \mathcal{C}$, and therefore $f^{-1}(A \times B) \in \mathcal{C}$, proving that $f \in \mathcal{M}(Z, X \times Y)$.
		\end{itemize}
\end{proof}

\begin{definition}[Vertical and horizontal sections of a set]%Thanks ProofWiki (Definition:Vertical Section of Set)
		Let $X$ and $Y$ be sets, and let $E \subseteq X \times Y$. Then, for all $x \in X$, we define the \textit{$x$-vertical section} $E_x$ of $E$ as $\{y \in Y \mid (x, y) \in E\}$. Similarly, for all $y \in Y$, we define the \textit{$y$-horizontal section} $E_y$ as $\{x \in X \mid (x, y) \in E\}$.
\end{definition}

\begin{theorem}[Complement of vertical/horizontal section is vertical/horizontal] \label{thm:complement-section-is-section}
		Let $X$ and $Y$ be sets, and let $E \subseteq X \times Y$. Then, for all $x \in X$, $(E_x)^c = (E^c)_x$. Similarly, for all $y \in Y$, $(E_y)^c = (E^c)_y$.
\end{theorem}

\begin{proof}
		Let $x \in X$. Then, we have:
				$$(E^c)_x = \{y \in Y \mid (x, y) \in E^c\} = \{y \in Y \mid (x, y) \in E\}^c = (E_x)^c$$
		Similarly, for $y \in Y$, $(E_y)^c = (E^c)_y$.
\end{proof}

\begin{theorem}[Union of vertical/horizontal sections is vertical/horizontal] \label{thm:union-section-is-section}
		Let $X$ and $Y$ be sets, and let $(E_i)_{i \in I}$ be a (potentially uncountable) family of sets of $X \times Y$. Then, for all $x \in X$, $(\bigcup_{i \in I} E_i)_x = \bigcup_{i \in I} (E_i)_x$. Similarly, for all $y \in Y$, $(\bigcup_{i \in I} E_i)_y = \bigcup_{i \in I} (E_i)_y$.
\end{theorem}

\begin{proof}
		Let $x \in X$. Then, we have:
		\begin{align*}
								(\bigcup_{i \in I} E_i)_x &= \{y \in Y \mid (x, y) \in \bigcup_{i \in I} E_i\}\\
														  &= \{y \in Y \mid \exists i \in I, (x, y) \in E_i\}\\
														  &= \{y \in Y \mid \exists i \in I, y \in (E_i)_x\}\\
														  &= \{y \in Y \mid y \in \bigcup_{i \in I} (E_i)_x\}\\
														  &= \bigcup_{i \in I} (E_i)_x
		\end{align*}
		Similarly, for $y \in Y$, we have $(\bigcup_{i \in I} E_i)_y = \bigcup_{i \in I} (E_i)_y$.
\end{proof}

\begin{theorem}[Vertical and horizontal sections of measurable sets are measurable] \label{thm:vertical-section-measurable-set-is-measurable} %Thanks Benjamin Charlier (proposition 4.12) and ProofWiki (Vertical Section of Measurable Set is Measurable)
		Let $(X, \mathcal{A})$ and $(Y, \mathcal{B})$ be measurable spaces, and let $E \in \mathcal{A} \otimes \mathcal{B}$. Then, for all $x \in X$, $E_x \in \mathcal{B}$. Similarly, for all $y \in Y$, $E_y \in \mathcal{A}$.
\end{theorem}

\begin{proof}
		Let $x \in X$. To prove that, for all $E \in \mathcal{A} \otimes \mathcal{B}$, $E_x \in \mathcal{B}$, we will prove that $\{E \in \mathcal{A} \otimes \mathcal{B} \mid E_x \in \mathcal{B}\} = \mathcal{A} \otimes \mathcal{B}$. Let's note $S$ for $\{E \in \mathcal{A} \otimes \mathcal{B} \mid E_x \in \mathcal{B}\}$. As we already have that $S \subseteq \mathcal{A} \otimes \mathcal{B}$, we just need to prove that $\mathcal{A} \otimes \mathcal{B} \subseteq S$. Since $\mathcal{A} \otimes \mathcal{B}$ is defined as the $\sigma$-algebra generated by $\{A \times B \mid (A, B) \in \mathcal{A} \times \mathcal{B}\}$, we just need to prove that $\{A \times B \mid (A, B) \in \mathcal{A} \times \mathcal{B}\} \subseteq S$ and that $S$ is a $\sigma$-algebra:
		\begin{itemize}
				\item Let's prove that  $\{A \times B \mid (A, B) \in \mathcal{A} \times \mathcal{B}\} \subseteq S$. Let $(A, B) \in \mathcal{A} \times \mathcal{B}$. 
				\begin{itemize}
						\item If $x \in A$, then we have:
								$$(A \times B)_x = \{y \in Y \mid (x, y) \in A \times B\} = \{y \in Y \mid y \in B\} = B \in \mathcal{B}$$
						\item If $x \notin A$, then we have:
								$$(A \times B)_x = \{y \in Y \mid (x, y) \in A \times B\} = \varnothing \in \mathcal{B}$$
				\end{itemize}
				Therefore, $(A \times B)_x \in \mathcal{B}$ in all cases, and since $A \times B \in \mathcal{A} \otimes \mathcal{B}$, then $A \times B \in S$. Therefore, $\{A \times B \mid (A, B) \in \mathcal{A} \times \mathcal{B}\} \subseteq S$.
				\item Let's prove that $S$ is a $\sigma$-algebra:
				\begin{itemize}
						\item $X \times Y \in \{A \times B \mid (A, B) \in \mathcal{A} \times \mathcal{B}\} \subseteq S$
						\item Let $E \in S$. Then, as $E \in \mathcal{A} \otimes \mathcal{B}$, we also have $E^c \in \mathcal{A} \otimes \mathcal{B}$. Furthermore, as we have $E_x \in \mathcal{B}$, then $(E^c)_x = (E_x)^c \in \mathcal{B}$, where the equality comes from theorem (\ref{thm:complement-section-is-section}). Therefore, $E^c \in S$.
						\item Let $(E_i)_{i\in\mathbb{N}}$ be a countable family of elements of $S$. Then, as for all $i \in \mathbb{N}$, $E_i \in \mathcal{A} \otimes \mathcal{B}$, then $\bigcup_{i \in \mathbb{N}} E_i \in \mathcal{A} \otimes \mathcal{B}$. Furthermore, since for all $i \in \mathbb{N}$, $(E_i)_x \in \mathcal{B}$, then $(\bigcup_{i\in\mathbb{N}} E_i)_x = \bigcup_{i\in\mathbb{N}} (E_i)_x \in \mathcal{B}$, where the equality comes from theorem (\ref{thm:union-section-is-section}). We therefore have that $\bigcup_{i\in\mathbb{N}} E_i \in S$.
				\end{itemize}
		\end{itemize}
		And therefore, $S = \mathcal{A} \otimes \mathcal{B}$, proving that for all $E \in \mathcal{A} \otimes \mathcal{B}$, $E_x \in \mathcal{B}$. Similarly, for all $E \in \mathcal{A} \otimes \mathcal{B}$, $E_y \in \mathcal{A}$.
\end{proof}

\begin{definition}[Vertical and horizontal sections of a mapping]%Thanks ProofWiki (Definition:Horizontal Section of Function) and (Definition:Vertical Section of Function) and Benjamin Charlier (definition 4.11)
		Let $X$, $Y$, and $Z$ be sets, and let $f : X \times Y \rightarrow Z$. For all $x \in X$, we define the \textit{$x$-vertical section} of $f$ as $f_x : Y \rightarrow Z$, $y \mapsto f(x, y)$. Similarly, for all $y \in Y$, we define the \textit{$y$-horizontal section} of $f$ as $f_y : X \rightarrow Z$, $x \mapsto f(x, y)$.
\end{definition}

\begin{theorem}[Vertical and horizontal sections of measurable mappings are measurable] \label{thm:sections-measurable-mappings-are-measurable}
		Let $(X, \mathcal{A})$, $(Y, \mathcal{B})$, and $(Z, \mathcal{C})$ be measurable spaces, and let $f \in \mathcal{M}(X \times Y, Z)$. Then, for all $x \in X$, $f_x \in \mathcal{M}(Y, Z)$, and for all $y \in Y$, $f_y \in \mathcal{M}(X, Z)$.
\end{theorem}

\begin{proof}
		Let $x \in X$. Then, for all $C \in \mathcal{C}$, we have:
		$$f_x^{-1}(C) = \{y \in Y \mid f_x(y) \in C\} = \{y \in Y \mid f(x, y) \in C\} = \{y \in Y \mid (x, y) \in f^{-1}(C)\} = (f^{-1}(C))_x$$
		As $f \in \mathcal{M}(X \times Y, Z)$, then $f^{-1}(C) \in \mathcal{X} \otimes \mathcal{Y}$. Therefore, from theorem (\ref{thm:vertical-section-measurable-set-is-measurable}), $(f^{-1}(C))_x \in \mathcal{B}$, and therefore $f_x^{-1}(C) \in \mathcal{B}$ from the above equality, which proves that $f_x \in \mathcal{M}(Y, Z)$. Similarly, for all $y \in Y$, $f_y \in \mathcal{M}(X, Z)$.
\end{proof}

\section{Product measure spaces and product measures}

\begin{definition}[Product measure spaces and product measures] %Thanks Proofwiki (Definition: Product Measure) and Benjamin Charlier (theorem 4.13 (1))
		Let $(X, \mathcal{A}, \mu)$ and $(Y, \mathcal{B}, \nu)$ be $\sigma$-finite measure spaces. There is a unique measure over $(X \times Y, \mathcal{A} \otimes \mathcal{B})$, denoted $\mu \times \nu$, such that for all $(A, B) \in \mathcal{A} \times \mathcal{B}$:
				$$(\mu \times \nu)(A \times B) = \mu(A)\nu(B)$$
		And we define the \textit{product measure space} of $(X, \mathcal{A}, \mu)$ and $(Y, \mathcal{B}, \nu)$ as $(X \times Y, \mathcal{A} \otimes \mathcal{B}, \mu \times \nu)$.
\end{definition}

\fbox{Prove the product measure indeed exists and is unique}

\begin{theorem}[Characteristic property of product measure] \label{thm:product-measure-charac} %Benjamin Charlier (theorem 4.13 (2)) and https://proofwiki.org/wiki/Measure_of_Horizontal_Section_of_Measurable_Set_gives_Measurable_Function
		Let $(X, \mathcal{A}, \mu)$ and $(Y, \mathcal{B}, \nu)$ be $\sigma$-finite measure spaces, and let $E \in \mathcal{A} \otimes \mathcal{B}$. Then, we have:
		\begin{itemize}
				\item $(x \mapsto \nu(E_x)) \in \mathcal{M}(X, [0, \infty])$ and $(y \mapsto \mu(E_y)) \in \mathcal{M}(Y, [0, \infty])$
				\item $(\mu \times \nu)(E) = \int_X \nu(E_x) \dd \mu(x) = \int_Y \mu(E_y) \dd \nu(y)$
		\end{itemize}
\end{theorem}

\begin{proof}
		\fbox{TO DO}
		%Maybe look at https://proofwiki.org/wiki/Measure_of_Horizontal_Section_of_Measurable_Set_gives_Measurable_Function
		%TODO
\end{proof}

\begin{theorem}[Vertical/horizontal section of characteristic function is the characteristic function of the vertical/horizontal section] \label{thm:section-charac-charac-section}%Thanks ProofWiki (Horizontal Section of Characteristic Function is Characteristic Function of Horizontal Section)
		Let $X$ and $Y$ be sets, and let $E \subseteq X \times Y$. Then, for all $x \in X$, $(\mathbbm{1}_E)_x = \mathbbm{1}_{E_x}$. Similarly, for all $y \in Y$, $(\mathbbm{1}_E)_y = \mathbbm{1}_{E_y}$.
\end{theorem}

\begin{proof}
		Let $x \in X$. Then for all $y \in Y$, we have:
				$$(\mathbbm{1}_E)_x(y) = \mathbbm{1}_{E}(x, y) = \begin{cases}1 & \tif (x, y) \in E\\0 & \tif (x, y) \notin E\end{cases} = \begin{cases}1 & \tif y \in E_x\\0 & \tif y \notin E_x\end{cases} = \mathbbm{1}_{E_x}(y)$$
		Proving that $(\mathbbm{1}_E)_x = \mathbbm{1}_{E_x}$. Similarly, for all $y \in Y$, $(\mathbbm{1}_E)_y = \mathbbm{1}_{E_y}$.
\end{proof}

\begin{theorem}[Integral of vertical/horizontal section of positive measurable function gives a measurable function] %Thanks ProofWiki (Integral of Horizontal Section of Measurable Function gives Measurable Function) and (Integral of Vertical Section of Measurable Function gives Measurable Function)
		Let $(X, \mathcal{A}, \mu)$ and $(Y, \mathcal{B}, \nu)$ be $\sigma$-finite measure spaces, and let $(X \times Y, \mathcal{A} \otimes \mathcal{B}, \mu \times \nu)$ be their product measure space. Let $f \in \mathcal{M}(X \times Y, [0, \infty])$ be a positive measurable function. Then, we have:
		\begin{itemize}
				\item $f_x \in \mathcal{M}(Y, [0, \infty])$ and $f_y \in \mathcal{M}(X, [0, \infty])$
				\item $g(x) = \int_Y f_x \dd \nu$ and $h(y) = \int_X f_y \dd \mu$ are measurable: $g \in \mathcal{M}(X, [0, \infty])$ and $h \in \mathcal{M}(Y, [0, \infty])$.%$(x \mapsto \int_Y f_x \dd \nu) \in \mathcal{M}(X, [0, \infty])$ and $(y \mapsto \int_X f_y \dd \mu)$
		\end{itemize}
\end{theorem}

\begin{proof}
		The first point is a special case of theorem (\ref{thm:sections-measurable-mappings-are-measurable}), and shows that the integrals in the second point are well-defined. To prove the second point, we will firstly prove it for when $f$ is a measurable characteristic function, then when $f$ is a a positive simple function, and finally when $f$ is a positive measurable function:
		\begin{itemize}
				\item Let's suppose $f$ is a measurable characteristic function, that is, a function of the form $\mathbbm{1}_{E}$ for $E \in \mathcal{A} \otimes \mathcal{B}$. It is indeed measurable (i.e. $\mathbbm{1}_E \in \mathcal{M}(X \times Y, [0, \infty])$) because it is a special case of a simple function. For all $x \in X$, we have:
						$$g(x) = \int_Y (\mathbbm{1}_E)_x \dd \nu = \int_Y \mathbbm{1}_{E_x} \dd \nu = \nu(E_x)$$
				where the second equality comes from theorem (\ref{thm:section-charac-charac-section}). From the above equality, we have that $g = (x \mapsto \nu(E_x))$, which from the first point of theorem (\ref{thm:product-measure-charac}), is measurable.
		\item Let's suppose $f$ is a positive simple function, that is, a function of the form $\sum_{i=1}^n c_i \mathbbm{1}_{A_i}(x)$ where $(c_1, \dots, c_n) \in [0, \infty[^n$ and where $(A_1, \dots, A_n)$ is a finite partition of $X$ with each $A_i$ being measurable.
						% From theorem (\ref{thm:section-charac-charac-section}), we have that $(\mathbbm{1}_E)_x = \mathbbm{1}_{E_x}$, and therefore, $\mathbbm{1}_{E_x} \in \mathcal{M}(Y, [0, \infty])$.
				%TODO
		\end{itemize}
\end{proof}


\begin{theorem}[Tonelli's theorem]
		Let $(X, \mathcal{A}, \mu)$ and $(Y, \mathcal{B}, \nu)$ be $\sigma$-finite measure spaces, and let $(X \times Y, \mathcal{A} \otimes \mathcal{B}, \mu \times \nu)$ be their product measure space. For all positive measurable function $f \in \mathcal{M}(X \times Y, [0, \infty])$, we have:
				$$\int_{X \times Y} f \dd (\mu \times \nu) = \int_X \left(\int_Y f(x, y) \dd \nu(y)\right) \dd \mu(x) = \int_Y \left(\int_X f(x, y) \dd \mu(x)\right) \dd \nu(y)$$
		Or equivalently:
				$$\int_{X \times Y} f \dd (\mu \times \nu) = \int_X \left(\int_Y f_x \dd \nu\right) \dd \mu = \int_Y \left(\int_X f_y \dd \mu\right) \dd \nu$$
\end{theorem} %TODO








\section{Probabilities}

\begin{definition}[Probability space] %Thanks ProofWiki
		A \textit{probability space} $(\Omega, \mathcal{A}, \P)$ is a measure space such that $\P[\Omega] = 1$. $\Omega$ is called a \textit{sample space} and its elements are called \textit{outcomes}. $\mathcal{A}$ is called an \textit{event space} and its elements are called \textit{events}. $\P$ is called a \textit{probability measure} (or a probability distribution).
\end{definition}

\begin{definition}[Image measure] %Thanks Proofwiki (Definition:Pushforward Measure)
		Let $(X, \mathcal{A}, \mu)$ be a measure space, let $(Y, \mathcal{B})$ be a measurable space, and let $f \in \mathcal{M}(X, Y)$ be a measurable mapping. We define the \textit{image measure} (or pushforward measure) of $\mu$ under $f$ as:
				$$f_*\mu : \mathcal{B} \rightarrow [0, \infty]$$
				$$B \mapsto \mu(f^{-1}(B))$$
				In other words, $f_*\mu = \mu \circ f^{-1}$. It is a measure over $(Y, \mathcal{B})$ because:
				\begin{itemize}
						\item $f_*\mu(\varnothing) = \mu(f^{-1}(\varnothing)) = \mu(\varnothing) = 0$
						\item For any coutable family $(B_i)_{i \in \mathbb{N}}$ of disjoint measurable sets of $\mathcal{B}$, we have:
								$$f_*\mu(\bigcup_{i\in\mathbb{N}} A_i) = \mu(f^{-1}(\bigcup_{i\in\mathbb{N}} A_i)) = \mu(\bigcup_{i\in\mathbb{N}} f^{-1}(A_i)) = \bigcup_{i\in\mathbb{N}} \mu(f^{-1}(A_i)) = \bigcup_{i\in\mathbb{N}} f_*\mu(A_i)$$
				\end{itemize}
\end{definition}


\begin{definition}[Random variable] %Thanks ProofWiki
		Let $(\Omega, \mathcal{A}, \P)$ be a probability space, and let $(E, \mathcal{B})$ be a measurable space. A random variable is a measurable mapping $X \in \mathcal{M}(\Omega, E)$.
\end{definition}

\begin{definition}[Probability measure of a random variable]
		Let $(\Omega, \mathcal{A}, \P)$ be a probability space, let $(E, \mathcal{B})$ be a measurable space, and let $X \in \mathcal{M}(\Omega, E)$ be a random variable. We define the probability measure $\P_X : \mathcal{B} \rightarrow [0, 1]$ of $X$ (also called the probability mass function of $X$) as $\P_X = X_*\P$. We already know that it is a measure, and it is a probability measure because $\P_X[E] = X_*\P[E] = \P[X^{-1}(E)] = \P[\Omega] = 1$. We often note $\P[X \in B]$ for $\P_X[B]$.
\end{definition}

\begin{example}
		Let $(\Omega, \mathcal{A}, \P)$ be a probability space, with $\Omega = \{\omega_1, \omega_2, \omega_3, \omega_4, \omega_5, \omega_6\}$, $\mathcal{A} = \mathcal{P}(\Omega)$, and $\P[A] = \frac{1}{6} \chi(A)$, where $\chi$ is the counting measure. Let's consider the random variable $X \in \mathcal{M}(\Omega, \mathbb{R})$ such that $X(\omega_i) = i^2$. Then, we have $\P[X \in \{1, \dots, 10\}] = \P_X[\{1, \dots, 10\}] = \P[X^{-1}(\{1, \dots, 10\})] = \P[\{\omega_1, \omega_2, \omega_3\}] = \frac{1}{6} \chi({\{\omega_1, \omega_2, \omega_3\}}) = \frac{1}{2}$.
\end{example}

\begin{definition}[Conditional probability] %Thanks ProofWiki (Definition:Conditional Probability) and Théorie des Probabilités of Bernard Candelpergher (page 110, bottom) and Benjamin Charlier
		Let $(\Omega, \mathcal{A}, \P)$ be a probability space. Then, for all event $A \in \mathcal{A}$ such that $\P[A] \neq 0$, we define the \textit{conditional probability} $\P_A : \mathcal{A} \rightarrow \mathbb{R}$ as:
				$$\P_A[B] = \frac{\P[A \cap B]}{\P[A]}$$
				which we often denote as $\P[B \mid A]$. It is indeed a probability measure over $(\Omega, \mathcal{A})$ because:
		\begin{itemize}
				\item $\P_A[\varnothing] = \frac{\P[A \cap \varnothing]}{\P[A]} = 0$
				\item For all countable family $(A_i)_{i\in\mathbb{N}}$ of distinct measurable sets, we have:
						$$\P_A[\bigcup_{i\in\mathbb{N}} A_i] = \frac{\P[A \cap \bigcup_{i\in\mathbb{N}} A_i]}{\P[A]} = \frac{\P[\bigcup_{i\in\mathbb{N}} A \cap A_i]}{\P[A]} = \frac{\sum_{i\in\mathbb{N}} \P[A \cap A_i]}{\P[A]} = \sum_{i\in\mathbb{N}} \frac{\P[A \cap A_i]}{\P[A]} = \sum_{i\in\mathbb{N}} \P_A[A_i]$$
				\item $\P_A[\Omega] = \frac{\P[A \cap \Omega]}{\P[A]} = \frac{\P[A]}{\P[A]} = 1$
		\end{itemize}
\end{definition}

%, let $(E, \mathcal{B})$ be a measurable space, and let $X \in \mathcal{M}(\Omega, E)$ be a random variable.

\begin{definition}[Expected value]
		Let $(\Omega, \mathcal{A}, \P)$ be a probability space, and $X \in L^1(\Omega)$ be a real random variable which is integrable. Then, we define the \textit{expected value} of $X$ as:
				$$\E{X} = \int_\Omega X \dd \P$$
\end{definition}

\begin{remark}
		Some authors talk about the expected value of a random variable as long as $\int_\Omega X^+ \dd \P$ and $\int_\Omega X^- \dd \P$ aren't both infinite, but they must be careful when adding or subtracting such expected values. We will talk about expected value only when the random variable is integrable.
\end{remark}

\begin{definition}[Conditional expected value] %
		Let $(\Omega, \mathcal{A}, \P)$ be a probability space, and let $X \in L^1(\Omega, \mathcal{A}, \P)$ be a real random variable which is integrable. Then, for all event $A \in \mathcal{A}$ such that $\P[A] \neq 0$, we define the \textit{conditional expected value} of $X$ as:
				$$\mathbb{E}_A[X] = \int_\Omega X \dd \P_A$$
		which we often denote as $\E{X \mid A}$. Note that this integral is defined \fbox{because $L^1(\Omega, \mathcal{A}, \P) = L^1(\Omega, \mathcal{A}, \P_A)$}.
\end{definition}

\begin{theorem}[Characteristic property of expected value] 
		Let $(\Omega, \mathcal{A}, \P)$ be a probability space, and let $X \in L^1(\Omega, \mathcal{A}, \P)$ be an integrable random variable. Then, for all event $A \in \mathcal{A}$ such that $\P[A] \neq 0$, we have:
				$$\E{X \mid A} = \frac{1}{\P[A]}\int_A X \dd \P$$
\end{theorem}

\begin{proof}
		\fbox{Requires many theorems about integrals}
\end{proof}


%https://en.wikipedia.org/wiki/Probability_density_function#Formal_definition
%https://proofwiki.org/wiki/Definition:Probability_Density_Function
%https://proofwiki.org/wiki/Definition:Conditional_Expectation
%https://en.wikipedia.org/wiki/Conditional_expectation
%https://en.wikipedia.org/wiki/Conditional_probability_distribution#Conditional_continuous_distributions
%https://en.wikipedia.org/wiki/Conditional_probability#Conditioning_on_an_event_of_probability_zero



\end{document}
